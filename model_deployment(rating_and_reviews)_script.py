# -*- coding: utf-8 -*-
"""Model Deployment(Rating and Reviews)_Script.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1hnEUEbm1jSvboZoNAt11uNk-ZVlZ7ydr

# 1. Install and Import Dependencies
"""

!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
#!pip install transformers requests beautifulsoup4 pandas numpy
!pip install simpletransformers requests beautifulsoup4 pandas numpy
!pip install sentencepiece
!pip install nltk
!pip install seaborn
!pip install matplotlib
import pandas as pd
import nltk
import seaborn as sea
import matplotlib as plt
import numpy as np
import xgboost as xgb
import pickle
import regex as re
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import accuracy_score, precision_score, roc_curve, auc, recall_score
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import torch
import requests
from bs4 import BeautifulSoup
import re

"""# 2. Instantiate LLM Model"""

import sentencepiece
from transformers import XLMRobertaTokenizer, XLMRobertaForSequenceClassification

# Install sentencepiece if not already installed
# You can run this in your terminal or command prompt
# pip install sentencepiece

# Load the tokenizer
tokenizer = XLMRobertaTokenizer.from_pretrained('akhooli/xlm-r-large-arabic-sent')

# Load the model
model = XLMRobertaForSequenceClassification.from_pretrained('akhooli/xlm-r-large-arabic-sent')

"""# 3. Encode and Calculate Sentiment

**Inputs**
"""

description = 'Behtareen Service Priceoye very good'
rating = '4'

"""**LLM Model Sentiment Analysis**"""

tokens = tokenizer.encode(description, return_tensors='pt')
result = model(tokens)
sentiment_score=int(torch.argmax(result.logits))+1
sentiment_score

"""**Decode LLM Model Results**"""

def decode_sentiment(sentiment_score):
    if sentiment_score == 1:
        return 'neutral'
    elif sentiment_score == 2:
        return 'negative'
    elif sentiment_score == 3:
        return 'positive'
    else:
        return 'unknown'

# Example usage:
#score = 2
LLM = decode_sentiment(sentiment_score)
print(f"Sentiment: {LLM}")

"""**Builting Features**"""

import pandas as pd
"""data = pd.read_excel('/content/Jan_24_Rating.xlsx')
data.head()"""
data = pd.DataFrame({
    'LLM': [LLM],
    'description': [description],
    'rating': [rating]
})

#data.head()

import pandas as pd
import regex as re
import numpy as np

# Assuming you have a DataFrame named 'data'

Positive_Strings = ['Alhumdulillah','Allhamdulliah', 'Alhamdulillah', 'Masha Allah','mashallah', 'Mashallah', 'MaShaAllah', 'Allah', 'Thank', 'thank', 'Thanks', 'Thank you', 'thank you',
                    'Behtareen','Behtereen', 'behtareen', 'awesome', 'Awesome', 'VIP', 'vip', 'Vip', 'Best', 'best', 'good product','Good packing', 'nyc', 'nice', 'Nice', 'Allaw', 'allaw',
                    'orginal product', 'thnx','Orignal', 'Acha product', 'Best', 'ZabbarDast', 'Zabrdast', 'zabrdast', 'Zbrdast', 'Satisfactory', 'satisfactory', 'satisfied', 'Satisfied', 'Satisfies',
                    'satisfying','Not bad','shukiya','acchi hai','Outstanding','keep it up','Aala product','geniue','safe','Wonderful','Great service','thank',
                    'Bhut he Aala', 'happy', 'Happy', '#Trusted', '#trusted', 'Trusted', 'perfect', 'Perfect', 'Excellent', 'appreciated', 'Highly recommend', 'Amazing', 'glad', 'Outstanding', 'Bhot khoob',
                    'Nice product','decent','value for money', 'value of money','Original Product','behtreeen','5 stars','Original product','Bohat ache','Unbeatable prices',
                    'Zbardast', 'Recommended.', 'Genuine', 'pretty good', 'high quality', 'Product original', 'Product is original', 'Shandar product', 'better quality', 'Good overall', 'Genuine product']


Negative_Strings = ['Bad','Bakwassssssss','Hats off', 'bad', 'Ghatya', 'ghatya', 'Fruad', 'fraud', 'bakwas', 'Bakwas', 'poor', 'Poor', 'missing', 'cheap', 'Cheap', 'not satisfied', 'not recommended', '3rd class',
                    'Not recommended', 'not good', 'local quality','waste of money', 'scratches', 'scratch', 'pathetic',
                    'Low quality', 'Baqwas','poor', 'faulty product']


# Conditions
conditions_accepted = (((data['LLM'].str.contains('Positive|positive', case=False)) &
    (data['rating'].astype(str).str.contains('4|5'))
  )|
                       (data['LLM'].str.contains('neutral|Neutral', case=False) &
                        data['rating'].astype(str).str.contains('4|5') &
                        data['description'].astype(str).str.contains('|'.join(Positive_Strings), case=False)&(~data['description'].isna()))|
                       (data['LLM'].str.contains('Neutral|neutral', case=False) &
                                  data['rating'].astype(str).str.contains('1|2|3') &
                                  data['description'].astype(str).str.contains('|'.join(Positive_Strings), case=False))|
                       (data['LLM'].str.contains('negative|Negative', case=False) &
                                  data['rating'].astype(str).str.contains('4|5') &
                                  data['description'].astype(str).str.contains('|'.join(Positive_Strings), case=False))|
                       (data['LLM'].str.contains('Positive|positive', case=False) &
                                  data['rating'].astype(str).str.contains('3')&
                        (~data['description'].isna())|(data['description'].astype(str).str.contains('|'.join(Positive_Strings), case=False)))|
                       (data['LLM'].str.contains('Positive|positive', case=False) &
                                  data['rating'].astype(str).str.contains('1|2') &
                                  data['description'].astype(str).str.contains('|'.join(Positive_Strings), case=False)

                    ))

conditions_rejected = ((data['LLM'].str.contains('Negative|negative', case=False) &
                        data['rating'].astype(str).str.contains('1|2|3')) |
                       (data['LLM'].str.contains('Negative|negative', case=False) &
                        data['rating'].astype(str).str.contains('1|2|3') &
                       (~data['description'].isna()))|
                       (data['LLM'].str.contains('neutral|Neutral', case=False) &
                        data['rating'].astype(str).str.contains('1|2') &
                        data['description'].astype(str).str.contains('|'.join(Negative_Strings), case=False)) |
                       (data['LLM'].str.contains('Negative|negative', case=False) &
                        data['rating'].astype(str).str.contains('4|5') &
                        data['description'].astype(str).str.contains('|'.join(Negative_Strings), case=False))|
                       (data['LLM'].str.contains('Positive|positive', case=False) &
                                  data['rating'].astype(str).str.contains('1|2') &
                                  data['description'].astype(str).str.contains('|'.join(Negative_Strings), case=False))|
                       (data['LLM'].str.contains('Neutral|neutral', case=False) &
                                  data['rating'].astype(str).str.contains('1|2|3') &
                                  data['description'].astype(str).str.contains('|'.join(Negative_Strings), case=False))

                       )

conditions_ignore = ~conditions_accepted & ~conditions_rejected

"""**Prediction on the basis of LLM And Features**

**Mati Bhai accepted k case mein, Hum Onclick function apply kray gy, on "accepted" Button. Baki jo Senerio hai, Us mein vese hee rehnain dena hai, QK 80% ACCEPT K  hee cases hotay hai**
"""

# Applying labels based on conditions
"""data['Labeled Result'] = np.select([conditions_accepted, conditions_rejected, conditions_ignore],
                                   ['accepted', 'rejected', 'ignore'],
                                   default='ignore')"""

result = np.select([conditions_accepted, conditions_rejected, conditions_ignore],
                                   ['accepted', 'rejected', 'ignore'],
                                   default='ignore')

result

# Display the resulting DataFrame
#data.to_excel('Labled_Data.xlsx', index =False)
#data
#data.to_excel('Data_Verifying_last.xlsx', index =False)

"""**Uses Trained Model For Prediction**

data['Feature_1'] = conditions_accepted
data['Feature_2'] = conditions_rejected
data['Feature_3'] = conditions_ignore
#data

data_to_model = data[['Feature_1', 'Feature_2', 'Feature_3']]
data_to_model

import pickle
import pandas as pd
from sklearn.preprocessing import LabelEncoder

# Load the trained SVM model
model_filename = '/content/Review_Rating_Model_SVM.pkl'
with open(model_filename, 'rb') as model_file:
    loaded_model = pickle.load(model_file)

# Use label encoding to convert textual labels to numerical values for the 'Feature' columns
label_encoder = LabelEncoder()

# Use .loc to set values in the original DataFrame
data_to_model.loc[:, 'Feature_1'] = label_encoder.fit_transform(data['Feature_1'])
data_to_model.loc[:, 'Feature_2'] = label_encoder.fit_transform(data['Feature_2'])
data_to_model.loc[:, 'Feature_3'] = label_encoder.fit_transform(data['Feature_3'])

def decode_prediction(y_pred_encoded):
    if y_pred_encoded == 0:
        return 'accepted'
    elif y_pred_encoded == 1:
        return 'rejected'
    elif y_pred_encoded == 2:
        return 'ignore'
    else:
        return 'unknown'

# Make predictions using the loaded model
y_pred_encoded = loaded_model.predict(data_to_model)
print(decode_prediction(y_pred_encoded))
"""

